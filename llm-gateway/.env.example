# LiteLLM Configuration
# Copy this file to .env and fill in your actual API keys

# PostgreSQL Database Password (required)
POSTGRES_PASSWORD=changeme_secure_password

# LiteLLM Admin Master Key (required)
# Generate a secure key: openssl rand -hex 32
LITELLM_MASTER_KEY=sk-admin-changeme

# Optional Redis Password (for distributed caching)
# REDIS_PASSWORD=changeme_redis_password

# ===== CLOUD PROVIDER API KEYS =====

# OpenAI (GPT-4, GPT-5, etc.)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-...

# Anthropic (Claude models)
# Get from: https://console.anthropic.com/account/keys
ANTHROPIC_API_KEY=sk-ant-api03-...

# DeepSeek
# Get from: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=sk-...

# Google (Gemini models)
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=AIza...

# OpenRouter (aggregator for many models)
# Get from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-...

# ===== FUTURE PROVIDERS (optional) =====

# Cohere
# Get from: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=...

# AI21
# Get from: https://studio.ai21.com/account/api-keys
AI21_API_KEY=...

# Replicate
# Get from: https://replicate.com/account/api-tokens
REPLICATE_API_KEY=...

# ===== LOCAL MODEL CONFIGURATION =====

# llama.cpp model settings
LLAMA_MODEL_PATH=/models/deepseek-coder-v2-lite-instruct-q8_0.gguf
LLAMA_CTX_SIZE=16384
LLAMA_N_PARALLEL=4

# vLLM model settings (future)
# VLLM_MODEL_PATH=/models/Qwen/Qwen2.5-Coder-7B-Instruct

# ===== OPTIONAL SETTINGS =====

# LiteLLM Virtual Key (generated by scripts/gen-virtual-key.sh)
# Used by Emacs and CLI tools instead of master key
LITELLM_VIRTUAL_KEY=

# Default model for CLI tools
DEFAULT_MODEL=coding-best

# Default base URL for API calls
DEFAULT_BASE_URL=http://localhost:4000/v1